import requests
from bs4 import BeautifulSoup
#爬取过程中，发现异常图书标签，作者标签位置不一致，可以使用try-except，跳过异常作者标签。
for s in range(1,51): #爬取当当网，图书畅销榜TOP500，共50页。
    url = "http://bang.dangdang.com/books/bestsellers/01.00.00.00.00.00-recent30-0-0-1-" + str(s)
    headers = {
        'user-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36 Edg/89.0.774.50'
    }
    shu_ju = requests.get(url=url, headers=headers).text
    shi_li_hua = BeautifulSoup(shu_ju, "lxml")
    ul_biao_qian=shi_li_hua.find('ul', attrs={'class': 'bang_list clearfix bang_list_mode'})
    zheng_ti = ul_biao_qian.find_all("li")
    # print(zheng_ti)

    biao = []
    for li in zheng_ti:
        shu_name = li.find_all('div', class_="name")[0].text
        # # print(shu_name)
        zhuo_zhe = li.find_all('div', attrs={'class': 'publisher_info'})[0].a.text
        # print(zhuo_zhe)
        chu_ban_she = li.find_all('div', attrs={'class': 'publisher_info'})[1].a.text
        # print(chu_ban_she)
        ping_lun = li.find_all('div', attrs={'class': 'star'})[0].a.text
        # print(ping_lun)
        zi_dian = {
            "书名": shu_name,
            "作者": zhuo_zhe,
            "出版社": chu_ban_she,
            "评论": ping_lun
        }
        biao.append(zi_dian)
        print(biao)
# with open("当当图书畅销榜TOP500.txt",'w',encoding='utf-8') as fp:
#     fp.write(biao)

